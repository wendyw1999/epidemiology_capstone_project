{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epidemiology Model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "- 1. COVID-19 US cases: Directly read data from JHU github repo.\n",
    "- 2. Mobility Data provided by Apple for each county in the U.S.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
    "us_confirmed_df = pd.read_csv(url, error_bad_lines=False)\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv'\n",
    "us_death_df = pd.read_csv(url, error_bad_lines=False)\n",
    "\n",
    "display(us_confirmed_df.head())\n",
    "display(us_death_df.head())\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "global_recover_df = pd.read_csv(url, error_bad_lines=False)\n",
    "display(global_recover_df.head())\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/descarteslabs/DL-COVID-19/master/DL-us-m50.csv\"\n",
    "mobility = pd.read_csv(url, error_bad_lines=False)\n",
    "display(mobility.head())\n",
    "us_confirmed_df = us_confirmed_df.loc[us_confirmed_df.Admin2 != \"Unassigned\"]\n",
    "us_death_df = us_death_df.loc[us_death_df.Admin2 != \"Unassigned\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_confirmed_df.loc[~us_confirmed_df[\"FIPS\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key variables of Epidemiology Model\n",
    "- I, the number of infected, is in the `us_comfirmed`\n",
    "- S, susceptible to COVID-19, is in `us_population` - `us_confirmed`, denoted as `us_susceptible`\n",
    "- R, removed, is the sum of recovered and deceased. \n",
    "- N, population\n",
    "\n",
    "## Parameters\n",
    "- Beta: the infection rate\n",
    "- D: number of days a patient can stay infected\n",
    "\n",
    "## Goal\n",
    "- With existing knowledge of I,S,R,and N, use gradient descent to figure out $\\theta$ = ($\\beta$, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "us_confirmed = us_confirmed_df.drop(['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State',\n",
    "       'Country_Region', 'Lat', 'Long_', 'Combined_Key'],axis=1).sum(axis=0).values\n",
    "us_death = us_death_df.drop(['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State',\n",
    "       'Country_Region', 'Lat', 'Long_', 'Combined_Key',\"Population\"],axis=1).sum(axis=0).values\n",
    "us_recovered = global_recover_df.loc[global_recover_df[\"Country/Region\"] == \"US\"].drop(\n",
    "    [\"Province/State\",\"Country/Region\",\"Lat\",\"Long\"],axis= 1).values[0]\n",
    "#us_removed = us_recovered+us_death\n",
    "us_removed = us_recovered+us_death\n",
    "#us_population = us_death_df.Population.sum()\n",
    "us_population = 1e7\n",
    "us_infected = us_confirmed \n",
    "us_susceptible = us_population - us_infected\n",
    "\n",
    "#test data\n",
    "us_removed = us_removed[0:100]\n",
    "us_susceptible = us_susceptible[0:100]\n",
    "us_infected = us_infected[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent to solve for $\\beta$ and $\\frac{1}{D}$\n",
    "\n",
    "Given: \n",
    "$\\begin{align*}\n",
    "  &\\xi = \\frac{1}{D} \\\\\n",
    "  &f_s(I_n,N,S_n) = -\\beta\\left(\\frac{I_n}{N}\\right) S_n, \\\\\n",
    "  &f_I(I_n,N,S_n) = - I\\xi + \\beta\\left(\\frac{I_n}{N}\\right) S_n,  \\\\\n",
    "  &f_R(I_n) = I_n\\xi, \\\\\n",
    "  &h=1\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "Plug the above values into\n",
    "$\\frac{1}{N} \\sum_{n=1}^N \\nabla_{\\theta} \\left( \\left({\\frac{s(n+1)-s(n)}{h} - f_s(s(n), I(n), R(n);\\theta)}\\right)^2\n",
    "+ \\left({\\frac{I(n+1)-I(n)}{h} - f_I(s(n), I(n), R(n;\\theta)}\\right)^2 + \\dots \\right)$\n",
    "\n",
    "To calculate the above the term, we need to use __chain rule__ to differentiate with respect to $\\beta$ and $\\xi$\n",
    "\n",
    "$\\nabla_{\\beta} = 2 \\cdot \\left(\\frac{S_{n+1} - S_{n}}{h} - \\left(-\\beta S_n  \\frac{I_n}{N}\\right) \\right) \\cdot \\left(S_n \\cdot \\frac{I_n}{N}\\right) + 2 \\cdot \\left(\\frac{I_{n+1} - I_{n}}{h}  - \\left( -\\xi_k I_n + \\beta_k \\frac{I_n}{N} S_n \\right)\\right) \\cdot \\left( -S_n \\cdot \\frac{I_n}{N}\\right)$\n",
    "\n",
    "$\\nabla_{\\xi} = 2 \\cdot \\left(\\frac{I_{n+1} - I_{n}}{h}  + \\left(I_n\\xi_k - \\beta_k \\frac{I_n}{N}S_n\\right) \\right) \\cdot \\left(I_n\\right) + 2 \\cdot \\left(\\frac{R_{n+1} - R_{n}}{h} - I_n\\xi_k\\right) \\cdot \\left( -I_n\\right)$\n",
    "\n",
    "\n",
    "\n",
    "## Tuning\n",
    "First initialize $\\theta$ at $\\beta = 0.2 $ and $\\xi = 0.1$\n",
    "\n",
    "\n",
    "Then, at each iteration update $\\beta$ and $\\xi$ according to the rules below\n",
    "\n",
    "\n",
    "$\\beta_{k+1} = \\beta_k - h_G \\partial_\\beta L(\\theta|s(1),\\dots,s(N)),$\n",
    "\n",
    "\n",
    "$\n",
    "\\xi_{k+1} = \\xi_k - h_G \\partial_\\xi L(\\theta|s(1),\\dots,s(N)).$\n",
    " where $h_G = 0.001$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_confirmed_df = us_confirmed_df.loc[us_confirmed_df.Admin2 != \"Unassigned\"]\n",
    "us_death_df = us_death_df.loc[us_death_df.Admin2 != \"Unassigned\"]\n",
    "def calculate_gradient(s,i,r,population,beta,epsilon):\n",
    "    result1 = 0 #continue adding to solve for beta\n",
    "    result2 = 0 #continue adding to solve for 1/D aka epsilon\n",
    "    for n in range(len(s)-1):\n",
    "        result1 += 2*(s[n+1]-s[n]+beta*s[n]*(i[n]/population))*(s[n]*i[n]/population)\n",
    "        result1 += 2*(i[n+1]-i[n]-beta*s[n]*(i[n]/population) + i[n]*epsilon)*(-s[n]*i[n]/population)\n",
    "        \n",
    "        result2 += 2*(i[n+1]-i[n]+i[n]*epsilon-beta*i[n]*s[n]/population)*(i[n])\n",
    "        result2 += 2*(r[n+1]-r[n]-i[n]*epsilon)*(-i[n])\n",
    "        \n",
    "    return result1,result2\n",
    "def calculate(s,i,r,population,learning_rate1,learning_rate2):\n",
    "    beta = 0.2\n",
    "    epsilon = 1/14\n",
    "    \n",
    "    loss = 0\n",
    "    length = len(s)\n",
    "    betas = []\n",
    "    ds = []\n",
    "    \n",
    "    for itera in range(1000): # do it for 10 iterations.\n",
    "        \n",
    "        loss1,loss2 = calculate_gradient(s,i,r,population,beta,epsilon)\n",
    "        beta_new = beta - learning_rate1* loss1/length #0.001 is the learning rate\n",
    "        epsilon_new = epsilon - learning_rate2 * loss2/length\n",
    "        if (beta_new == beta) & (epsilon_new == epsilon):\n",
    "            print(beta_new)\n",
    "            print(1/epsilon_new)\n",
    "            break\n",
    "        beta = beta_new\n",
    "        epsilon = epsilon_new\n",
    "        betas.append(beta)\n",
    "        ds.append(1/epsilon)\n",
    "\n",
    "    return betas,ds\n",
    "\n",
    "def get_county(start,days,county_code = 1001):\n",
    "    \n",
    "    county_confirmed = us_confirmed_df.loc[us_confirmed_df.FIPS == county_code].drop(['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State',\n",
    "           'Country_Region', 'Lat', 'Long_', 'Combined_Key'],axis=1).sum(axis=0).values\n",
    "    county_death = us_death_df.loc[us_death_df.FIPS == county_code].drop(['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State',\n",
    "           'Country_Region', 'Lat', 'Long_', 'Combined_Key',\"Population\"],axis=1).sum(axis=0).values\n",
    "    county_population = us_death_df.loc[us_death_df.FIPS ==county_code].Population.sum()\n",
    "    county_infected = county_confirmed\n",
    "    county_removed = county_death\n",
    "    county_susceptible = county_population - county_infected\n",
    "    return county_susceptible[start:days+start],county_infected[start:start+days],county_removed[start:start+days],county_population\n",
    "def get_state(start,days,state_name = \"Washington\"):\n",
    "    \n",
    "    county_confirmed = us_confirmed_df.loc[us_confirmed_df.Province_State == state_name].drop(['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State',\n",
    "           'Country_Region', 'Lat', 'Long_', 'Combined_Key'],axis=1).sum(axis=0).values\n",
    "    county_death = us_death_df.loc[us_death_df.Province_State == state_name].drop(['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State',\n",
    "           'Country_Region', 'Lat', 'Long_', 'Combined_Key',\"Population\"],axis=1).sum(axis=0).values\n",
    "    county_population = us_death_df.loc[us_death_df.Province_State ==state_name].Population.sum()\n",
    "    county_infected = county_confirmed\n",
    "    county_removed = county_death\n",
    "    county_susceptible = county_population - county_infected\n",
    "    return county_susceptible[start:start + days],county_infected[start:start + days],county_removed[start:days+start],county_population\n",
    "def get_country(start,days,country_name = \"US\"):\n",
    "    \n",
    "    county_confirmed = us_confirmed_df.loc[us_confirmed_df.Country_Region == country_name].drop(['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State',\n",
    "           'Country_Region', 'Lat', 'Long_', 'Combined_Key'],axis=1).sum(axis=0).values\n",
    "    county_death = us_death_df.loc[us_death_df.Country_Region == country_name].drop(['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State',\n",
    "           'Country_Region', 'Lat', 'Long_', 'Combined_Key',\"Population\"],axis=1).sum(axis=0).values\n",
    "    county_population = us_death_df.loc[us_death_df.Country_Region ==country_name].Population.sum()\n",
    "    country_recovered = global_recover_df.loc[global_recover_df[\"Country/Region\"] == country_name].drop(\n",
    "    [\"Province/State\",\"Country/Region\",\"Lat\",\"Long\"],axis= 1).values[0]\n",
    "    county_infected = county_confirmed\n",
    "    county_removed = county_death + country_recovered\n",
    "    county_susceptible = county_population - county_infected\n",
    "    return county_susceptible[start:start+days],county_infected[start:start+days],county_removed[start:start+days],county_population\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    county_code = 1005\n",
    "    \n",
    "    #s,i,r,p = get_county(70,1003)\n",
    "    #s,i,r,p = get_state(20,40,\"Washington\")\n",
    "    s,i,r,p = get_country(30,37)    \n",
    "    learning_rate1 = 1e-3/p*60\n",
    "    learning_rate2= 1e-3/p*60\n",
    "    betas,ds = calculate(s,i,r,p,learning_rate1,learning_rate2)\n",
    "    plt.plot(betas)\n",
    "    plt.show()\n",
    "    plt.plot(ds)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "\n",
    "us = geopandas.read_file(\"/home/caw062/template/data/county_boundary/cb_2018_us_county_500k.shp\")\n",
    "us_confirmed_df[\"GEOID\"] = us_confirmed_df[\"UID\"].apply(lambda x:str(x)[3:])\n",
    "merged = us_confirmed_df.merge(us,on=\"GEOID\",how=\"left\")\n",
    "gdf = geopandas.GeoDataFrame(\n",
    "    merged, geometry=merged[\"geometry\"])\n",
    "map1 = gdf.loc[gdf[\"Province_State\"] == \"California\"].plot(column = \"11/12/20\",\n",
    "                                                    figsize = (10,10),legend = True)\n",
    "centers = gdf.centroid\n",
    "points_gdf = gdf.copy()\n",
    "points_gdf[\"geometry\"] = centers\n",
    "ca_points = points_gdf.loc[points_gdf[\"Province_State\"] == \"California\"]\n",
    "plt.title(\"California Confirmed Cases, Newest\")\n",
    "for x, y, label in zip(ca_points.geometry.x, ca_points.geometry.y, ca_points[\"Admin2\"]):\n",
    "    map1.annotate(label, xy=(x-0.5, y), xytext=(2, 2), textcoords=\"offset points\",color = \"White\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "us_confirmed_df = us_confirmed_df.loc[us_confirmed_df.Long_ < -50]\n",
    "states = geopandas.read_file(\"/home/caw062/template/data/state_boundary/cb_2018_us_state_500k.shp\")\n",
    "us_confirmed_df[\"STATEFP\"] = us_confirmed_df[\"UID\"].apply(lambda x:str(x)[3:5])\n",
    "us_confirmed_df_by_state = us_confirmed_df.groupby(\"STATEFP\").agg({\"11/12/20\":\"sum\"})\n",
    "merged = us_confirmed_df_by_state.merge(states,on=\"STATEFP\",how=\"left\").dropna()\n",
    "merged = merged.loc[~merged[\"STUSPS\"].isin([\"HI\",\"AK\"])]\n",
    "gdf = geopandas.GeoDataFrame(\n",
    "    merged, geometry=merged[\"geometry\"])\n",
    "\n",
    "centers = gdf.centroid\n",
    "points_gdf = gdf.copy()\n",
    "points_gdf[\"geometry\"] = centers\n",
    "\n",
    "map1 = gdf.plot(column = \"11/12/20\",figsize = (10,10),legend = True)\n",
    "plt.title(\"US Confirmed Cases, by State\")\n",
    "for x, y, label in zip(points_gdf.geometry.x, points_gdf.geometry.y, points_gdf[\"STUSPS\"]):\n",
    "    map1.annotate(label, xy=(x-0.5, y), xytext=(2, 2), textcoords=\"offset points\",color = \"White\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "us_death_df = us_death_df.loc[us_death_df.Long_ < -50]\n",
    "states = geopandas.read_file(\"/home/caw062/template/data/state_boundary/cb_2018_us_state_500k.shp\")\n",
    "us_death_df[\"STATEFP\"] = us_death_df[\"UID\"].apply(lambda x:str(x)[3:5])\n",
    "us_death_df_by_state = us_death_df.groupby(\"STATEFP\").agg({\"11/12/20\":\"sum\"})\n",
    "merged = us_death_df_by_state.merge(states,on=\"STATEFP\",how=\"left\").dropna()\n",
    "merged = merged.loc[~merged[\"STUSPS\"].isin([\"HI\",\"AK\"])]\n",
    "gdf = geopandas.GeoDataFrame(\n",
    "    merged, geometry=merged[\"geometry\"])\n",
    "map3 = gdf.plot(column = \"11/12/20\",figsize = (10,10),legend = True)\n",
    "plt.title(\"US Death, newest\")\n",
    "for x, y, label in zip(points_gdf.geometry.x, points_gdf.geometry.y, points_gdf[\"STUSPS\"]):\n",
    "    map3.annotate(label, xy=(x-0.5, y), xytext=(2, 2), textcoords=\"offset points\",color = \"White\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = geopandas.read_file(\"/home/caw062/template/data/state_boundary/cb_2018_us_state_500k.shp\")\n",
    "mobility_by_state = mobility.loc[mobility.admin_level == 1].rename({\"admin1\":\"NAME\"},axis = 1)\n",
    "\n",
    "merged = mobility_by_state.merge(states,on=\"NAME\",how=\"left\")\n",
    "merged = merged.loc[~merged[\"STUSPS\"].isin([\"HI\",\"AK\"])]\n",
    "gdf = geopandas.GeoDataFrame(\n",
    "    merged, geometry=merged[\"geometry\"])\n",
    "map4 = gdf.plot(column = \"2020-11-10\",figsize = (10,10),legend = True)\n",
    "plt.title(\"US Mobility Indicator, Newest\")\n",
    "for x, y, label in zip(points_gdf.geometry.x, points_gdf.geometry.y, points_gdf[\"STUSPS\"]):\n",
    "    map4.annotate(label, xy=(x-0.5, y), xytext=(2, 2), textcoords=\"offset points\",color = \"White\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "fontP = FontProperties()\n",
    "fontP.set_size('xx-small')\n",
    "\n",
    "def death_multi_plot(n, df, level, start_date= '1/22/20'):\n",
    "    '''\n",
    "    n: number of regions\n",
    "    df: Dataframe of death cases\n",
    "    level: region level: admin2/ province/ state\n",
    "    '''\n",
    "    randomlist = []\n",
    "    for i in range(0,n):\n",
    "        n = random.randint(0,df.shape[0])\n",
    "        randomlist.append(n)\n",
    "        print(randomlist)\n",
    "    for j in randomlist:\n",
    "        target_j = df.loc[j,:]\n",
    "        targetj_dth_info= target_j[start_date:]\n",
    "        target_region = str(target_j[level])\n",
    "        yj= list (targetj_dth_info)\n",
    "        xj = list (targetj_dth_info.index)\n",
    "        plt.plot(xj, yj, label=target_region)\n",
    "    plt.xlabel('Dates')\n",
    "    plt.ylabel('Number of Dath Cases')\n",
    "    plt.title('Death Cases of 10 regions in '+ level+ ' level')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', prop=fontP)\n",
    "    plt.figure(figsize=[20,15])\n",
    "    plt.show()\n",
    "    return\n",
    "death_multi_plot(5,us_death_df,\"Province\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat as nbf\n",
    "\n",
    "nb = nbf.v4.new_notebook()\n",
    "text = \"\"\"\\\n",
    "# My first automatic Jupyter Notebook\n",
    "This is an auto-generated notebook.\"\"\"\n",
    "\n",
    "code = \"\"\"\\\n",
    "%pylab inline\n",
    "hist(normal(size=2000), bins=50);\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
    "us_confirmed_df = pd.read_csv(url, error_bad_lines=False)\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv'\n",
    "us_death_df = pd.read_csv(url, error_bad_lines=False)\n",
    "\n",
    "display(us_confirmed_df.head())\n",
    "display(us_death_df.head())\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "global_recover_df = pd.read_csv(url, error_bad_lines=False)\n",
    "display(global_recover_df.head())\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/descarteslabs/DL-COVID-19/master/DL-us-m50.csv\"\n",
    "mobility = pd.read_csv(url, error_bad_lines=False)\n",
    "display(mobility.head())\n",
    "us_confirmed_df = us_confirmed_df.loc[us_confirmed_df.Admin2 != \"Unassigned\"]\n",
    "us_death_df = us_death_df.loc[us_death_df.Admin2 != \"Unassigned\"]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "nb['cells'] = [nbf.v4.new_markdown_cell(text),\n",
    "               nbf.v4.new_code_cell(code)]\n",
    "fname = 'test.ipynb'\n",
    "\n",
    "with open(fname, 'w') as f:\n",
    "    nbf.write(nb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = points_gdf.loc[points_gdf.Province_State == \"California\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install arcpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out neighbors\n",
    "from arcgis import *\n",
    "gis1=GIS()\n",
    "gis = GIS(\"https://ucsdonline.maps.arcgis.com/home/item.html?id=c74bf4d93f514f0296c1ffd6dda71a73\", client_id='S9hCtNsAKhoTpS87')\n",
    "print(\"Successfully logged in as: \" + gis.properties.user.username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USA COUNTIES: https://www.arcgis.com/home/item.html?id=7566e0221e5646f99ea249a197116605\n",
    "counties_ = gis.content.get('7566e0221e5646f99ea249a197116605')\n",
    "counties = counties_.layers[0].query().sdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "def generate_df(nbr):  \n",
    "    fips = list(nbr.FIPS)\n",
    "    for i in range(len(fips)):\n",
    "        if not fips[i]>0:\n",
    "            fips[i]=fips[i-1]\n",
    "    nbr['FIPS']=fips\n",
    "    idx = []\n",
    "    for i in range(nbr.shape[0]):\n",
    "        center = nbr.loc[i,'FIPS'] \n",
    "        nearby = nbr.loc[i,'N-FIPS']\n",
    "        if center == nearby:\n",
    "            idx.append(i)\n",
    "    nbr = nbr.drop(idx)\n",
    "    nbr=nbr.reset_index(drop=True)\n",
    "    return nbr\n",
    "def get_neighbors(code,nbr):\n",
    "    dic = {}\n",
    "    keys = nbr.FIPS\n",
    "    values=nbr['N-FIPS']\n",
    "    res = defaultdict(list) \n",
    "    for i, j in zip(keys, values): \n",
    "        res[i].append(j)\n",
    "    return res[code]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('county_adjacency.txt', sep= '\\t',encoding= 'unicode_escape', names =['Center','FIPS','NBR','N-FIPS'])\n",
    "test= generate_df(df)[['FIPS','N-FIPS']]\n",
    "\n",
    "fp = \"info.shp\"\n",
    "data = gpd.read_file(fp)\n",
    "data = data[['FIPS','LON','LAT']]\n",
    "data['FIPS']=pd.to_numeric(data['FIPS'])\n",
    "nei_data = data.rename(columns = {'FIPS':'N-FIPS','LAT':\"N-LAT\",\"LON\":\"N-LON\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In four directions, +x, -x, +y, -y, set center as (0,0);\n",
    "\n",
    "\"\"\"\n",
    "step1 = test.merge(data, on='FIPS', how='left')\n",
    "step2 = step1.merge(nei_data, on ='N-FIPS', how='left' )\n",
    "step2['LON_diff'] = step2['LON']-step2['N-LON']\n",
    "step2['LAT_diff'] = step2['LAT']-step2['N-LAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1021, 1047, 1051, 1085, 1101]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_neighbors(1001,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>N-FIPS</th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>N-LON</th>\n",
       "      <th>N-LAT</th>\n",
       "      <th>LON_diff</th>\n",
       "      <th>LAT_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>1021</td>\n",
       "      <td>-86.6428</td>\n",
       "      <td>32.5349</td>\n",
       "      <td>-86.7188</td>\n",
       "      <td>32.8479</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>-0.3130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>1047</td>\n",
       "      <td>-86.6428</td>\n",
       "      <td>32.5349</td>\n",
       "      <td>-87.1065</td>\n",
       "      <td>32.3258</td>\n",
       "      <td>0.4637</td>\n",
       "      <td>0.2091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>1051</td>\n",
       "      <td>-86.6428</td>\n",
       "      <td>32.5349</td>\n",
       "      <td>-86.1492</td>\n",
       "      <td>32.5966</td>\n",
       "      <td>-0.4936</td>\n",
       "      <td>-0.0617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>1085</td>\n",
       "      <td>-86.6428</td>\n",
       "      <td>32.5349</td>\n",
       "      <td>-86.6501</td>\n",
       "      <td>32.1548</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.3801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>1101</td>\n",
       "      <td>-86.6428</td>\n",
       "      <td>32.5349</td>\n",
       "      <td>-86.2076</td>\n",
       "      <td>32.2202</td>\n",
       "      <td>-0.4352</td>\n",
       "      <td>0.3147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FIPS  N-FIPS      LON      LAT    N-LON    N-LAT  LON_diff  LAT_diff\n",
       "0  1001.0    1021 -86.6428  32.5349 -86.7188  32.8479    0.0760   -0.3130\n",
       "1  1001.0    1047 -86.6428  32.5349 -87.1065  32.3258    0.4637    0.2091\n",
       "2  1001.0    1051 -86.6428  32.5349 -86.1492  32.5966   -0.4936   -0.0617\n",
       "3  1001.0    1085 -86.6428  32.5349 -86.6501  32.1548    0.0073    0.3801\n",
       "4  1001.0    1101 -86.6428  32.5349 -86.2076  32.2202   -0.4352    0.3147"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>N-FIPS</th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>N-LON</th>\n",
       "      <th>N-LAT</th>\n",
       "      <th>LON_diff</th>\n",
       "      <th>LAT_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>1021</td>\n",
       "      <td>-86.6428</td>\n",
       "      <td>32.5349</td>\n",
       "      <td>-86.7188</td>\n",
       "      <td>32.8479</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>-0.3130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>1047</td>\n",
       "      <td>-86.6428</td>\n",
       "      <td>32.5349</td>\n",
       "      <td>-87.1065</td>\n",
       "      <td>32.3258</td>\n",
       "      <td>0.4637</td>\n",
       "      <td>0.2091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>1051</td>\n",
       "      <td>-86.6428</td>\n",
       "      <td>32.5349</td>\n",
       "      <td>-86.1492</td>\n",
       "      <td>32.5966</td>\n",
       "      <td>-0.4936</td>\n",
       "      <td>-0.0617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>1085</td>\n",
       "      <td>-86.6428</td>\n",
       "      <td>32.5349</td>\n",
       "      <td>-86.6501</td>\n",
       "      <td>32.1548</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.3801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>1101</td>\n",
       "      <td>-86.6428</td>\n",
       "      <td>32.5349</td>\n",
       "      <td>-86.2076</td>\n",
       "      <td>32.2202</td>\n",
       "      <td>-0.4352</td>\n",
       "      <td>0.3147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1003.0</td>\n",
       "      <td>1025</td>\n",
       "      <td>-87.7171</td>\n",
       "      <td>30.7278</td>\n",
       "      <td>-87.8309</td>\n",
       "      <td>31.6709</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>-0.9431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1003.0</td>\n",
       "      <td>1053</td>\n",
       "      <td>-87.7171</td>\n",
       "      <td>30.7278</td>\n",
       "      <td>-87.1616</td>\n",
       "      <td>31.1262</td>\n",
       "      <td>-0.5555</td>\n",
       "      <td>-0.3984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1003.0</td>\n",
       "      <td>1097</td>\n",
       "      <td>-87.7171</td>\n",
       "      <td>30.7278</td>\n",
       "      <td>-88.2018</td>\n",
       "      <td>30.7943</td>\n",
       "      <td>0.4847</td>\n",
       "      <td>-0.0665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1003.0</td>\n",
       "      <td>1099</td>\n",
       "      <td>-87.7171</td>\n",
       "      <td>30.7278</td>\n",
       "      <td>-87.3658</td>\n",
       "      <td>31.5706</td>\n",
       "      <td>-0.3513</td>\n",
       "      <td>-0.8428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1003.0</td>\n",
       "      <td>1129</td>\n",
       "      <td>-87.7171</td>\n",
       "      <td>30.7278</td>\n",
       "      <td>-88.2071</td>\n",
       "      <td>31.4077</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>-0.6799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1003.0</td>\n",
       "      <td>12033</td>\n",
       "      <td>-87.7171</td>\n",
       "      <td>30.7278</td>\n",
       "      <td>-87.3777</td>\n",
       "      <td>30.7012</td>\n",
       "      <td>-0.3394</td>\n",
       "      <td>0.0266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1005.0</td>\n",
       "      <td>1011</td>\n",
       "      <td>-85.3932</td>\n",
       "      <td>31.8696</td>\n",
       "      <td>-85.7161</td>\n",
       "      <td>32.1005</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>-0.2309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1005.0</td>\n",
       "      <td>1045</td>\n",
       "      <td>-85.3932</td>\n",
       "      <td>31.8696</td>\n",
       "      <td>-85.6110</td>\n",
       "      <td>31.4318</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.4378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1005.0</td>\n",
       "      <td>1067</td>\n",
       "      <td>-85.3932</td>\n",
       "      <td>31.8696</td>\n",
       "      <td>-85.2414</td>\n",
       "      <td>31.5147</td>\n",
       "      <td>-0.1518</td>\n",
       "      <td>0.3549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1005.0</td>\n",
       "      <td>1109</td>\n",
       "      <td>-85.3932</td>\n",
       "      <td>31.8696</td>\n",
       "      <td>-85.9409</td>\n",
       "      <td>31.8024</td>\n",
       "      <td>0.5477</td>\n",
       "      <td>0.0672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1005.0</td>\n",
       "      <td>1113</td>\n",
       "      <td>-85.3932</td>\n",
       "      <td>31.8696</td>\n",
       "      <td>-85.1849</td>\n",
       "      <td>32.2884</td>\n",
       "      <td>-0.2083</td>\n",
       "      <td>-0.4188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1005.0</td>\n",
       "      <td>13061</td>\n",
       "      <td>-85.3932</td>\n",
       "      <td>31.8696</td>\n",
       "      <td>-84.9803</td>\n",
       "      <td>31.6264</td>\n",
       "      <td>-0.4129</td>\n",
       "      <td>0.2432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1005.0</td>\n",
       "      <td>13239</td>\n",
       "      <td>-85.3932</td>\n",
       "      <td>31.8696</td>\n",
       "      <td>-85.0188</td>\n",
       "      <td>31.8674</td>\n",
       "      <td>-0.3744</td>\n",
       "      <td>0.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1005.0</td>\n",
       "      <td>13259</td>\n",
       "      <td>-85.3932</td>\n",
       "      <td>31.8696</td>\n",
       "      <td>-84.8351</td>\n",
       "      <td>32.0785</td>\n",
       "      <td>-0.5581</td>\n",
       "      <td>-0.2089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1007.0</td>\n",
       "      <td>1021</td>\n",
       "      <td>-87.1264</td>\n",
       "      <td>32.9986</td>\n",
       "      <td>-86.7188</td>\n",
       "      <td>32.8479</td>\n",
       "      <td>-0.4076</td>\n",
       "      <td>0.1507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS  N-FIPS      LON      LAT    N-LON    N-LAT  LON_diff  LAT_diff\n",
       "0   1001.0    1021 -86.6428  32.5349 -86.7188  32.8479    0.0760   -0.3130\n",
       "1   1001.0    1047 -86.6428  32.5349 -87.1065  32.3258    0.4637    0.2091\n",
       "2   1001.0    1051 -86.6428  32.5349 -86.1492  32.5966   -0.4936   -0.0617\n",
       "3   1001.0    1085 -86.6428  32.5349 -86.6501  32.1548    0.0073    0.3801\n",
       "4   1001.0    1101 -86.6428  32.5349 -86.2076  32.2202   -0.4352    0.3147\n",
       "5   1003.0    1025 -87.7171  30.7278 -87.8309  31.6709    0.1138   -0.9431\n",
       "6   1003.0    1053 -87.7171  30.7278 -87.1616  31.1262   -0.5555   -0.3984\n",
       "7   1003.0    1097 -87.7171  30.7278 -88.2018  30.7943    0.4847   -0.0665\n",
       "8   1003.0    1099 -87.7171  30.7278 -87.3658  31.5706   -0.3513   -0.8428\n",
       "9   1003.0    1129 -87.7171  30.7278 -88.2071  31.4077    0.4900   -0.6799\n",
       "10  1003.0   12033 -87.7171  30.7278 -87.3777  30.7012   -0.3394    0.0266\n",
       "11  1005.0    1011 -85.3932  31.8696 -85.7161  32.1005    0.3229   -0.2309\n",
       "12  1005.0    1045 -85.3932  31.8696 -85.6110  31.4318    0.2178    0.4378\n",
       "13  1005.0    1067 -85.3932  31.8696 -85.2414  31.5147   -0.1518    0.3549\n",
       "14  1005.0    1109 -85.3932  31.8696 -85.9409  31.8024    0.5477    0.0672\n",
       "15  1005.0    1113 -85.3932  31.8696 -85.1849  32.2884   -0.2083   -0.4188\n",
       "16  1005.0   13061 -85.3932  31.8696 -84.9803  31.6264   -0.4129    0.2432\n",
       "17  1005.0   13239 -85.3932  31.8696 -85.0188  31.8674   -0.3744    0.0022\n",
       "18  1005.0   13259 -85.3932  31.8696 -84.8351  32.0785   -0.5581   -0.2089\n",
       "19  1007.0    1021 -87.1264  32.9986 -86.7188  32.8479   -0.4076    0.1507"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting \n",
    "- After finding the most likely parameters, we can generate future forecasting from the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCSDESRI123\n",
    "\n",
    "\n",
    "#us_death = [0., 0., 0., 0., 1., 3., 8., 10., 13., 16., 17., 18., 23., 24., 26., 31., 39., 41., 51., 61., 73., 99., 122., 153., 209., 276., 349., 471., 599., 803., 1061., 1318., 1720., 2202., 2578., 3186., 4090.]\n",
    "\n",
    "def sim_fun_ODE(s,i,beta, N, D, int_steps, length):\n",
    "  S = np.zeros(length)\n",
    "  I = np.zeros(length)\n",
    "  S[0] = s[0]\n",
    "  I[0] = i[0]\n",
    "  dt = 1.0/int_steps\n",
    "  for l in range(length-1):\n",
    "    for i in range(int_steps):\n",
    "      S[l] = S[l] - beta*I[l]/N*S[l]*dt\n",
    "      I[l] = I[l] + (-I[l]/D + beta*I[l]/N*S[l])*dt\n",
    "    S[l+1] = S[l]\n",
    "    I[l+1] = I[l]\n",
    "  return S, I\n",
    "\n",
    "def sim_fun_SDE(s,i,beta, N, D, int_steps, length):\n",
    "  S = np.zeros(length)\n",
    "  I = np.zeros(length)\n",
    "  S[0] = s[0]\n",
    "  I[0] = i[0]\n",
    "  dt = 1.0/int_steps\n",
    "  for l in range(length-1):\n",
    "    for i in range(int_steps):\n",
    "      noise_matrix = np.matrix([[beta*I[l]*S[l]/N,-beta*I[l]*S[l]/N],[-beta*I[l]*S[l]/N, beta*I[l]*S[l]/N + I[l]/D]])\n",
    "      normal_noise = np.matmul(la.sqrtm(noise_matrix), np.random.normal((1,2)))\n",
    "      S[l] = S[l] - beta*I[l]/N*S[l]*dt + np.sqrt(dt)*normal_noise[0]\n",
    "      I[l] = I[l] + (-I[l]/D + beta*I[l]/N*S[l])*dt + np.sqrt(dt)*normal_noise[1]\n",
    "    S[l+1] = S[l]\n",
    "    I[l+1] = I[l]\n",
    "    return S, I\n",
    "length = 60\n",
    "\n",
    "beta = 0.0609266174999754\n",
    "D = 145.8343055068469\n",
    "N = p    # population size\n",
    "\n",
    "int_steps = 20\n",
    "plt.scatter(y=i,x=range(0,len(i),1))\n",
    "S_ODE, I_ODE = sim_fun_ODE(s,i,beta, N, D, int_steps, length)\n",
    "S_SDE, I_SDE = sim_fun_SDE(s,i,beta, N, D, int_steps, length)\n",
    "plt.plot(I_ODE,label='ODE result')\n",
    "#plt.plot(I_SDE,label='SDE result')\n",
    "\n",
    "plt.xlabel('Time (days)')\n",
    "plt.ylabel('Persons')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "##beta = 0.3                  # infection rate\n",
    "#D = 7                   # average duration of the infection\n",
    "#N = 300000000.0/10000.0     # population size\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# simulations of the ODE/SDE SIR model:\n",
    "length = 150\n",
    "int_steps = 20\n",
    "N = 300000000.0/10000.0     # population size\n",
    "\n",
    "# D = 5.0                    # average duration of the infection\n",
    "D = 7.0*0.7                    # average duration of the infection\n",
    "beta = 0.26 + 1.0/D         # infection rate\n",
    "S_ODE_5, I_ODE_5 = sim_fun_ODE(s,i,beta, N, D, int_steps, length)\n",
    "\n",
    "D = 7.0                    # average duration of the infection\n",
    "beta = 0.26 + 1.0/D         # infection rate\n",
    "S_ODE_7, I_ODE_7 = sim_fun_ODE(s,i,beta, N, D, int_steps, length)\n",
    "\n",
    "# D = 10.0                    # average duration of the infection\n",
    "D = 7.0*1.2                    # average duration of the infection\n",
    "beta = 0.26 + 1.0/D         # infection rate\n",
    "S_ODE_10, I_ODE_10 = sim_fun_ODE(s,i,beta, N, D, int_steps, length)\n",
    "\n",
    "\n",
    "D = 1.0/( 1.0/(7.0*0.7) - 1.0/7.0 + 1.0/28.0 )                    # average duration of the infection\n",
    "beta = 0.26 + 1.0/D         # infection rate\n",
    "S_ODE_20, I_ODE_20 = sim_fun_ODE(s,i,beta, N, D, int_steps, length)\n",
    "\n",
    "D = 28.0                    # average duration of the infection\n",
    "beta = 0.26 + 1.0/D         # infection rate\n",
    "S_ODE_28, I_ODE_28 = sim_fun_ODE(s,i,beta, N, D, int_steps, length)\n",
    "\n",
    "D = 1.0/( 1.0/28.0-1.0/7.0+1.0/(7.0*1.2) )                    # average duration of the infection\n",
    "beta = 0.26 + 1.0/D         # infection rate\n",
    "S_ODE_30, I_ODE_30 = sim_fun_ODE(s,i,beta, N, D, int_steps, length)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x= np.linspace(1.0, 150.0, 150)\n",
    "ax.plot(x, I_ODE_7, label='D=7')\n",
    "ax.plot(x, I_ODE_28, label='D=28')\n",
    "ax.scatter(range(0,len(us_death)-19,1), us_death[19:], color = 'black', marker = 'o', label='data points')\n",
    "ax.fill_between(x, I_ODE_5, I_ODE_10, color='b', alpha=0.1)\n",
    "ax.fill_between(x, I_ODE_20, I_ODE_30, color='r', alpha=0.1)\n",
    "plt.xlabel('Time (days)', fontsize=18)\n",
    "plt.ylabel('Number of Infected', fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.show()\n",
    "plt.savefig(\"epi_comp.eps\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
